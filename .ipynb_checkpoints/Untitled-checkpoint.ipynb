{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Untitled.ipynb\" file should have a proper unambiguous name\n",
    "\n",
    "\n",
    "I see you have a lot of markdown cells, but not with much actual text in them. This is not bad, but there could be a lot more context and subject matter knowledge you can add to a lot of this. I know this is a preliminary capstone, so you're still adding to it, but there is a LOT more to add regarding the markdown cells, explaining your workflow, your observations, and any other deductions you might have.\n",
    "\n",
    "Many of the simple functions are inefficient. For example, for the country_map function, you could simply use:\n",
    "def country_map(x):\n",
    "    return x == \"United States\"\n",
    "The text for the graphs are way too small, increase the text size for your graphs so they are readabled. Also, make sure not to use 0 and 1 for the gender legend. Instead, use \"Non-female\" and \"female\" to make it clear to the reader what those abstract numbers actually represent.\n",
    "You have a lot of solid EDA, which is great!\n",
    "There are some cells which seem you used to quickly check for some output, but DIDN'T include any markdown explaining the output. For example: np.mean(y) Make sure to either add markdown to explain what you're doing any why or remove these cells up before submitting.\n",
    "Your functions are nice and simple - be sure to include some documentation within the function (comments) about how the function works and what the output is supposed to be.\n",
    "There should be a cross validation score for EVERY model (including the baseline), how else will you know you can trust your test score!\n",
    "Your modeling workflow is out of order - you fitted a Decision tree AFTER a random forest, and same with Bagging Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = ['Survey Year', 'Timestamp', 'Country', 'PrimaryDatabase', 'YearsWithThisDatabase',\n",
    "             'EmploymentStatus', 'JobTitle','CompanyEmployeesOverall','ManageStaff', 'Education', \n",
    "             'EducationIsComputerRelated', 'Certifications', 'HoursWorkedPerWeek','SalaryUSD',\n",
    "             'LookingForAnotherJob', 'CareerPlansThisYear', 'YearsWithThisTypeOfJob', 'Gender']\n",
    "\n",
    "df = pd.read_excel(\"./datasets/2019_Data_Professional_Salary_Survey_Responses.xlsx\",\n",
    "                      skiprows= 3,usecols= keep_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_map(x):\n",
    "    return x == \"United States\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Country'] = df['Country'].map(country_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        True\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "6888    False\n",
       "6889    False\n",
       "6890    False\n",
       "6891     True\n",
       "6892    False\n",
       "Name: Country, Length: 6893, dtype: bool"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(color_codes = True)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "RANDOM_STATE = 2341"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy = pd.read_csv('./datasets/cleaned_dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_dummy.drop(columns = ['SalaryUSD','Timestamp', 'Survey Year'])\n",
    "\n",
    "#Create separate object for target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_dummy['SalaryUSD']\n",
    "\n",
    "#np.mean(y)\n",
    "\n",
    "#### Train and Test Splits\n",
    "\n",
    "#train test split to help check model\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                        random_state = RANDOM_STATE)\n",
    "\n",
    "#### Data Scaling\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "\n",
    "X_train_sc = ss.transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)\n",
    "\n",
    "#With all our models, we will use RMSE as the regression metric to measure the success of our models. RMSE works well for us because it is given in the units of our target variable and can easily tell us the error in our predictions. Our goal is to minimize the RMSE as much as possible to get it close to 0.\n",
    "\n",
    "def rmse(model, X, y):\n",
    "    \n",
    "    predictions = model.predict(X)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y, predictions))\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Train RMSE:  57965.304395185034\n",
      "Baseline Test RMSE:  57179.03514526216\n"
     ]
    }
   ],
   "source": [
    "base = DummyRegressor(strategy=\"mean\")\n",
    "\n",
    "# Fitting our baseline model: \n",
    "base.fit(X_train, y_train)\n",
    "\n",
    "# Calculating training and testing scores: \n",
    "\n",
    "print(\"Baseline Train RMSE: \", rmse(base, X_train,y_train))\n",
    "print(\"Baseline Test RMSE: \", rmse(base, X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,\n",
       "                                                 criterion='friedman_mse',\n",
       "                                                 init=None, learning_rate=0.1,\n",
       "                                                 loss='ls', max_depth=3,\n",
       "                                                 max_features=None,\n",
       "                                                 max_leaf_nodes=None,\n",
       "                                                 min_impurity_decrease=0.0,\n",
       "                                                 min_impurity_split=None,\n",
       "                                                 min_samples_leaf=1,\n",
       "                                                 min_samples_split=2,\n",
       "                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                 n_estimators=100,\n",
       "                                                 n_iter_n...\n",
       "                                                 validation_fraction=0.1,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'alpha': [0.9], 'learning_rate': [0.01, 0.1, 0.2],\n",
       "                         'max_depth': [None, 3, 5, 7],\n",
       "                         'max_features': ['auto', 0.25, 0.5, 0.75, None],\n",
       "                         'min_samples_leaf': [1, 2, 4, 5],\n",
       "                         'min_samples_split': [5, 10, 15],\n",
       "                         'n_estimators': [20, 50, 70]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tuning params\n",
    "tuned_params = {'learning_rate': [0.01, 0.1, 0.2], \n",
    "                'n_estimators': [20, 50, 70], \n",
    "               'max_depth' : [None, 3, 5, 7],\n",
    "               'max_features' : ['auto', .25, .5, .75, None],\n",
    "                'min_samples_split': [5, 10, 15], \n",
    "                'min_samples_leaf': [1, 2, 4, 5],\n",
    "               'alpha': [0.9]}\n",
    "               \n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "# Instantiate model\n",
    "gradient_model = GridSearchCV(GradientBoostingRegressor(random_state= RANDOM_STATE),\n",
    "                         param_grid=tuned_params, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit model\n",
    "gradient_model.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.9,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 3,\n",
       " 'max_features': 0.25,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 70}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Regressor Model Train RMSE: 44523.41733157255\n",
      "Gradient Regressor Model Test RMSE: 49570.674646423344\n"
     ]
    }
   ],
   "source": [
    "print(f'Gradient Regressor Model Train RMSE: {rmse(gradient_model, X_train_sc, y_train)}')\n",
    "print(f'Gradient Regressor Model Test RMSE: {rmse(gradient_model, X_test_sc, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                             criterion='mse', max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             max_samples=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=100, n_jobs=None,\n",
       "                                             oob_score=False, random_state=2341,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_depth': [None, 3, 5, 7],\n",
       "                         'max_features': ['auto', 0.25, 0.02, 0.15],\n",
       "                         'max_samples': [None, 1, 3, 5, 7],\n",
       "                         'min_samples_leaf': [2, 4, 5],\n",
       "                         'min_samples_split': [5, 10, 15],\n",
       "                         'n_estimators': [300, 400, 450, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tuning params\n",
    "tuned_params = {'n_estimators': [300, 400, 450, 500],\n",
    "                'min_samples_split': [5, 10, 15], \n",
    "                'min_samples_leaf': [ 2, 4, 5],\n",
    "               'max_depth' : [None, 3, 5, 7],\n",
    "                'max_features' : ['auto', .25, .02, .15],\n",
    "                 'max_samples' : [None, 1, 3, 5, 7]}\n",
    "\n",
    "# Instantiate model\n",
    "rf_model = GridSearchCV(RandomForestRegressor(random_state= RANDOM_STATE), tuned_params, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit model\n",
    "rf_model.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None,\n",
       " 'max_features': 0.25,\n",
       " 'max_samples': None,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 15,\n",
       " 'n_estimators': 450}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Train RMSE: 42744.2735089099\n",
      "Random Forest Model Test RMSE: 49264.696703187255\n"
     ]
    }
   ],
   "source": [
    "print(f'Random Forest Model Train RMSE: {rmse(rf_model, X_train_sc, y_train)}')\n",
    "print(f'Random Forest Model Test RMSE: {rmse(rf_model, X_test_sc, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "heelllldnjnjn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dnjenjnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
