{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(color_codes = True)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "RANDOM_STATE = 2341"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy = pd.read_csv('./datasets/cleaned_dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_dummy.drop(columns = ['SalaryUSD','Timestamp', 'Survey Year'])\n",
    "\n",
    "#Create separate object for target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_dummy['SalaryUSD']\n",
    "\n",
    "#np.mean(y)\n",
    "\n",
    "#### Train and Test Splits\n",
    "\n",
    "#train test split to help check model\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                        random_state = RANDOM_STATE)\n",
    "\n",
    "#### Data Scaling\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "\n",
    "X_train_sc = ss.transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)\n",
    "\n",
    "#With all our models, we will use RMSE as the regression metric to measure the success of our models. RMSE works well for us because it is given in the units of our target variable and can easily tell us the error in our predictions. Our goal is to minimize the RMSE as much as possible to get it close to 0.\n",
    "\n",
    "def rmse(model, X, y):\n",
    "    \n",
    "    predictions = model.predict(X)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y, predictions))\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Train RMSE:  57965.304395185034\n",
      "Baseline Test RMSE:  57179.03514526216\n"
     ]
    }
   ],
   "source": [
    "base = DummyRegressor(strategy=\"mean\")\n",
    "\n",
    "# Fitting our baseline model: \n",
    "base.fit(X_train, y_train)\n",
    "\n",
    "# Calculating training and testing scores: \n",
    "\n",
    "print(\"Baseline Train RMSE: \", rmse(base, X_train,y_train))\n",
    "print(\"Baseline Test RMSE: \", rmse(base, X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,\n",
       "                                                 criterion='friedman_mse',\n",
       "                                                 init=None, learning_rate=0.1,\n",
       "                                                 loss='ls', max_depth=3,\n",
       "                                                 max_features=None,\n",
       "                                                 max_leaf_nodes=None,\n",
       "                                                 min_impurity_decrease=0.0,\n",
       "                                                 min_impurity_split=None,\n",
       "                                                 min_samples_leaf=1,\n",
       "                                                 min_samples_split=2,\n",
       "                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                 n_estimators=100,\n",
       "                                                 n_iter_n...\n",
       "                                                 validation_fraction=0.1,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'alpha': [0.9], 'learning_rate': [0.01, 0.1, 0.2],\n",
       "                         'max_depth': [None, 3, 5, 7],\n",
       "                         'max_features': ['auto', 0.25, 0.5, 0.75, None],\n",
       "                         'min_samples_leaf': [1, 2, 4, 5],\n",
       "                         'min_samples_split': [5, 10, 15],\n",
       "                         'n_estimators': [20, 50, 70]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tuning params\n",
    "tuned_params = {'learning_rate': [0.01, 0.1, 0.2], \n",
    "                'n_estimators': [20, 50, 70], \n",
    "               'max_depth' : [None, 3, 5, 7],\n",
    "               'max_features' : ['auto', .25, .5, .75, None],\n",
    "                'min_samples_split': [5, 10, 15], \n",
    "                'min_samples_leaf': [1, 2, 4, 5],\n",
    "               'alpha': [0.9]}\n",
    "               \n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "# Instantiate model\n",
    "gradient_model = GridSearchCV(GradientBoostingRegressor(random_state= RANDOM_STATE),\n",
    "                         param_grid=tuned_params, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit model\n",
    "gradient_model.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.9,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 3,\n",
       " 'max_features': 0.25,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 70}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Regressor Model Train RMSE: 44523.41733157255\n",
      "Gradient Regressor Model Test RMSE: 49570.674646423344\n"
     ]
    }
   ],
   "source": [
    "print(f'Gradient Regressor Model Train RMSE: {rmse(gradient_model, X_train_sc, y_train)}')\n",
    "print(f'Gradient Regressor Model Test RMSE: {rmse(gradient_model, X_test_sc, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                             criterion='mse', max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             max_samples=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=100, n_jobs=None,\n",
       "                                             oob_score=False, random_state=2341,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_depth': [None, 3, 5, 7],\n",
       "                         'max_features': ['auto', 0.25, 0.02, 0.15],\n",
       "                         'max_samples': [None, 1, 3, 5, 7],\n",
       "                         'min_samples_leaf': [2, 4, 5],\n",
       "                         'min_samples_split': [5, 10, 15],\n",
       "                         'n_estimators': [300, 400, 450, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tuning params\n",
    "tuned_params = {'n_estimators': [300, 400, 450, 500],\n",
    "                'min_samples_split': [5, 10, 15], \n",
    "                'min_samples_leaf': [ 2, 4, 5],\n",
    "               'max_depth' : [None, 3, 5, 7],\n",
    "                'max_features' : ['auto', .25, .02, .15],\n",
    "                 'max_samples' : [None, 1, 3, 5, 7]}\n",
    "\n",
    "# Instantiate model\n",
    "rf_model = GridSearchCV(RandomForestRegressor(random_state= RANDOM_STATE), tuned_params, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit model\n",
    "rf_model.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None,\n",
       " 'max_features': 0.25,\n",
       " 'max_samples': None,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 15,\n",
       " 'n_estimators': 450}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Train RMSE: 42744.2735089099\n",
      "Random Forest Model Test RMSE: 49264.696703187255\n"
     ]
    }
   ],
   "source": [
    "print(f'Random Forest Model Train RMSE: {rmse(rf_model, X_train_sc, y_train)}')\n",
    "print(f'Random Forest Model Test RMSE: {rmse(rf_model, X_test_sc, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
